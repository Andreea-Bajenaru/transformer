{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os, gzip, pickle, random, re, sys\n",
    "\n",
    "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
    "IMDB_FILE = 'imdb.{}.pkl.gz'\n",
    "\n",
    "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
    "\n",
    "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
    "\n",
    "    cst = 'char' if char else 'word'\n",
    "\n",
    "    imdb_url = IMDB_URL.format(cst)\n",
    "    imdb_file = IMDB_FILE.format(cst)\n",
    "\n",
    "    if not os.path.exists(imdb_file):\n",
    "        wget.download(imdb_url)\n",
    "\n",
    "    with gzip.open(imdb_file) as file:\n",
    "        sequences, labels, i2w, w2i = pickle.load(file)\n",
    "\n",
    "    if voc is not None and voc < len(i2w):\n",
    "        nw_sequences = {}\n",
    "\n",
    "        i2w = i2w[:voc]\n",
    "        w2i = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "        mx, unk = voc, w2i['.unk']\n",
    "        for key, seqs in sequences.items():\n",
    "            nw_sequences[key] = []\n",
    "            for seq in seqs:\n",
    "                seq = [s if s < mx else unk for s in seq]\n",
    "                nw_sequences[key].append(seq)\n",
    "\n",
    "        sequences = nw_sequences\n",
    "\n",
    "    if final:\n",
    "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
    "\n",
    "    # Make a validation split\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "\n",
    "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
    "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
    "        if i in val_ind:\n",
    "            x_val.append(s)\n",
    "            y_val.append(l)\n",
    "        else:\n",
    "            x_train.append(s)\n",
    "            y_train.append(l)\n",
    "\n",
    "    return (x_train, y_train), \\\n",
    "           (x_val, y_val), \\\n",
    "           (i2w, w2i), 2\n",
    "\n",
    "\n",
    "def gen_sentence(sent, g):\n",
    "\n",
    "    symb = '_[a-z]*'\n",
    "\n",
    "    while True:\n",
    "\n",
    "        match = re.search(symb, sent)\n",
    "        if match is None:\n",
    "            return sent\n",
    "\n",
    "        s = match.span()\n",
    "        sent = sent[:s[0]] + random.choice(g[sent[s[0]:s[1]]]) + sent[s[1]:]\n",
    "\n",
    "def gen_dyck(p):\n",
    "    open = 1\n",
    "    sent = '('\n",
    "    while open > 0:\n",
    "        if random.random() < p:\n",
    "            sent += '('\n",
    "            open += 1\n",
    "        else:\n",
    "            sent += ')'\n",
    "            open -= 1\n",
    "\n",
    "    return sent\n",
    "\n",
    "def gen_ndfa(p):\n",
    "\n",
    "    word = random.choice(['abc!', 'uvw!', 'klm!'])\n",
    "\n",
    "    s = ''\n",
    "    while True:\n",
    "        if random.random() < p:\n",
    "            return 's' + s + 's'\n",
    "        else:\n",
    "            s+= word\n",
    "\n",
    "def load_brackets(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='dyck')\n",
    "\n",
    "def load_ndfa(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='ndfa')\n",
    "\n",
    "def load_toy(n=50_000, char=True, seed=0, name='lang'):\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    if name == 'lang':\n",
    "        sent = '_s'\n",
    "\n",
    "        toy = {\n",
    "            '_s': ['_s _adv', '_np _vp', '_np _vp _prep _np', '_np _vp ( _prep _np )', '_np _vp _con _s' , '_np _vp ( _con _s )'],\n",
    "            '_adv': ['briefly', 'quickly', 'impatiently'],\n",
    "            '_np': ['a _noun', 'the _noun', 'a _adj _noun', 'the _adj _noun'],\n",
    "            '_prep': ['on', 'with', 'to'],\n",
    "            '_con' : ['while', 'but'],\n",
    "            '_noun': ['mouse', 'bunny', 'cat', 'dog', 'man', 'woman', 'person'],\n",
    "            '_vp': ['walked', 'walks', 'ran', 'runs', 'goes', 'went'],\n",
    "            '_adj': ['short', 'quick', 'busy', 'nice', 'gorgeous']\n",
    "        }\n",
    "\n",
    "        sentences = [ gen_sentence(sent, toy) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s : len(s))\n",
    "\n",
    "    elif name == 'dyck':\n",
    "\n",
    "        sentences = [gen_dyck(7./16.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    elif name == 'ndfa':\n",
    "\n",
    "        sentences = [gen_ndfa(1./4.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    else:\n",
    "        raise Exception(name)\n",
    "\n",
    "    tokens = set()\n",
    "    for s in sentences:\n",
    "\n",
    "        if char:\n",
    "            for c in s:\n",
    "                tokens.add(c)\n",
    "        else:\n",
    "            for w in s.split():\n",
    "                tokens.add(w)\n",
    "\n",
    "    i2t = [PAD, START, END, UNK] + list(tokens)\n",
    "    t2i = {t:i for i, t in enumerate(i2t)}\n",
    "\n",
    "    sequences = []\n",
    "    for s in sentences:\n",
    "        if char:\n",
    "            tok = list(s)\n",
    "        else:\n",
    "            tok = s.split()\n",
    "        sequences.append([t2i[t] for t in tok])\n",
    "\n",
    "    return sequences, (i2t, t2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['possibly', 'the', 'best', 'movie', 'ever', 'created', 'in', 'the', 'history', 'of', 'jeffrey', 'combs', 'career', 'and', 'one', 'that', 'should', 'be', 'looked', 'upon', 'by', 'all', 'talent', 'in', 'hollywood', 'for', 'his', 'versatility', 'charisma', 'and', 'uniqueness', 'he', 'brings', 'through', 'his', 'characters', 'and', 'his', 'knowledge', 'of', 'acting']\n"
     ]
    }
   ],
   "source": [
    "print([i2w[w] for w in x_train[141]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(w2i['.pad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_and_conversion(batch_sequences, pad_index):\n",
    "    max_length = max(len(seq) for seq in batch_sequences)\n",
    "\n",
    "    padded_sequences= []\n",
    "    for seq in batch_sequences:\n",
    "        padded_seq = seq + [pad_index] * (max_length - len(seq))\n",
    "        padded_sequences.append(padded_seq)\n",
    "\n",
    "    # Conversion to a torch tensor\n",
    "    batch_tensor = torch.tensor(padded_sequences, dtype=torch.long)\n",
    "    \n",
    "    return batch_tensor\n",
    "\n",
    "x_train = padding_and_conversion(x_train, pad_index=w2i[PAD])\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=300, hidden_size=300, num_classes=2):\n",
    "        super(SequenceModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(embedding_size, hidden_size)\n",
    "\n",
    "        # Global max pooling\n",
    "        self.global_max_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(inputs)\n",
    "\n",
    "        # Linear layer\n",
    "        linear_output = self.linear(embedded)\n",
    "\n",
    "        # ReLu activation function\n",
    "        activations = F.relu(linear_output)\n",
    "\n",
    "        # Max pooling\n",
    "        pooled_output = self.global_max_pooling(activations.transpose(1, 2)).squeeze(-1) \n",
    "\n",
    "        # Output layer\n",
    "        output = self.output_layer(pooled_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99430"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Validation Accuracy: 85.16%\n",
      "Epoch 2/5, Validation Accuracy: 87.48%\n",
      "Epoch 3/5, Validation Accuracy: 86.46%\n",
      "Epoch 4/5, Validation Accuracy: 86.62%\n",
      "Epoch 5/5, Validation Accuracy: 87.18%\n",
      "Final Validation Accuracy: 87.18%\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(w2i)\n",
    "model = SequenceModel(vocab_size)\n",
    "loss_fn =F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "x_val = padding_and_conversion(x_val, pad_index=w2i[PAD])\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            output = model(inputs)\n",
    "            predicted_labels = torch.argmax(output, dim=1)\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Validation Accuracy: 86.60%\n",
      "Epoch 2/7, Validation Accuracy: 86.38%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 93\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     92\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 93\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(output, labels)\n\u001b[0;32m     95\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[44], line 66\u001b[0m, in \u001b[0;36mSimpleSequenceModel.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     63\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_max_pooling(activations\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Self-attention\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m attended_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Output layer\u001b[39;00m\n\u001b[0;32m     69\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[44], line 26\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m dot \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(queries, keys\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m     25\u001b[0m dot \u001b[38;5;241m=\u001b[39m dot \u001b[38;5;241m/\u001b[39m (k \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m---> 26\u001b[0m dot \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(dot, values)\u001b[38;5;241m.\u001b[39mview(b, h, t, s)\n\u001b[0;32m     29\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(b, t, s \u001b[38;5;241m*\u001b[39m h)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1839\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1841\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads=4, mask=False):\n",
    "        super().__init__()\n",
    "        assert k % heads == 0\n",
    "        self.k, self.heads = k, heads\n",
    "        self.tokeys = nn.Linear(k, k, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k, bias=False)\n",
    "        self.tovalues = nn.Linear(k, k, bias=False)\n",
    "        self.unifyheads = nn.Linear(k, k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, k = x.size()\n",
    "        h = self.heads\n",
    "        s = self.k // h\n",
    "\n",
    "        keys = self.tokeys(x).view(b, t, h, s)\n",
    "        queries = self.toqueries(x).view(b, t, h, s)\n",
    "        values = self.tovalues(x).view(b, t, h, s)\n",
    "\n",
    "        keys = keys.transpose(1, 2).contiguous().view(b * h, t, s) # do this differently\n",
    "        queries = queries.transpose(1, 2).contiguous().view(b * h, t, s)  #Write an attention function, not self attention\n",
    "        values = values.transpose(1, 2).contiguous().view(b * h, t, s)  #(mh) attention (q,k,v)\n",
    "\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        dot = dot / (k ** (1/2))\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "\n",
    "        out = torch.bmm(dot, values).view(b, h, t, s)\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
    "\n",
    "        return self.unifyheads(out)\n",
    "\n",
    "class SimpleSequenceModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size=300, hidden_size=300, num_classes=2):\n",
    "        super(SimpleSequenceModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "\n",
    "        # Linear layer\n",
    "        self.linear = nn.Linear(embedding_size, hidden_size)\n",
    "\n",
    "        # Global max pooling\n",
    "        self.global_max_pooling = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Self-attention layer\n",
    "        self.self_attention = MultiHeadSelfAttention(hidden_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(inputs)\n",
    "\n",
    "        # Linear layer\n",
    "        linear_output = self.linear(embedded)\n",
    "\n",
    "        # ReLu activation function\n",
    "        activations = F.relu(linear_output)\n",
    "\n",
    "        # Max pooling\n",
    "        pooled_output = self.global_max_pooling(activations.transpose(1, 2)).squeeze(-1) \n",
    "\n",
    "        # Self-attention\n",
    "        attended_output = self.self_attention(activations)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.output_layer(pooled_output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "vocab_size = len(w2i)\n",
    "model = SimpleSequenceModel(vocab_size)\n",
    "loss_fn = F.cross_entropy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 7\n",
    "\n",
    "x_val = padding_and_conversion(x_val, pad_index=w2i[PAD])\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            output = model(inputs)\n",
    "            predicted_labels = torch.argmax(output, dim=1)\n",
    "            correct += (predicted_labels == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Accuracy: {val_accuracy:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
